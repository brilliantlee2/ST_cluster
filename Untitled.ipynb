{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c42f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79907c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Module):\n",
    "    from collections import OrderedDict\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        if len(args) == 1 and isinstance(args[0], OrderedDict): # 如果传入的是一个OrderedDict\n",
    "            for key, module in args[0].items():\n",
    "                self.add_module(key, module)  # add_module方法会将module添加进self._modules(一个OrderedDict)\n",
    "        else:  # 传入的是一些Module\n",
    "            for idx, module in enumerate(args):\n",
    "                self.add_module(str(idx), module)\n",
    "    def forward(self, input):\n",
    "        # self._modules返回一个 OrderedDict，保证会按照成员添加时的顺序遍历成员\n",
    "        for module in self._modules.values():\n",
    "            input = module(input)\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74172c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(2, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e90caf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1879, -0.1695, -0.0053, -0.1500,  0.0868, -0.0626,  0.0985,  0.1401,\n",
       "         -0.0947,  0.1601],\n",
       "        [ 0.1292, -0.1508,  0.0435, -0.0532,  0.0928, -0.1235,  0.0850,  0.1866,\n",
       "         -0.1704,  0.1055]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10), \n",
    "        )\n",
    "print(net)\n",
    "net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91cac466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_block(in_features, out_features, p_drop):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features, out_features),\n",
    "        nn.BatchNorm1d(out_features, momentum=0.01, eps=0.001),\n",
    "        nn.ELU(),\n",
    "        nn.Dropout(p=p_drop),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3b11ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDR(nn.Module):\n",
    "    def __init__(self, input_dim, params):\n",
    "        super(SEDR, self).__init__()\n",
    "        self.alpha = 1.0\n",
    "        self.latent_dim = params.gcn_hiddenn2+params.feat_hidde2\n",
    "\n",
    "        # feature autoencoder  encoder和decoder都是全连接层\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.add_module('encoder_L1', full_block(input_dim, params.feat_hidden1, params.p_drop))\n",
    "        self.encoder.add_module('encoder_L2', full_block(params.feat_hidden1, params.feat_hidden2, params.p_drop))\n",
    "        \n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.add_module('decoder_L0', full_block(self.latent_dim, input_dim, params.p_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dafaa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a92bc159",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEDR_test(nn.Module):\n",
    "    def __init__(self,input_dim, params):\n",
    "        super(SEDR_test,self).__init__()\n",
    "        self.encoder = nn.Sequential()\n",
    "        self.encoder.add_module('encoder_L1', full_block(input_dim, params.feat_hidden1, params.p_drop))\n",
    "        self.encoder.add_module('encoder_L2', full_block(params.feat_hidden1, params.feat_hidden2, params.p_drop))\n",
    "        self.decoder = nn.Sequential()\n",
    "        self.decoder.add_module('decoder_L0', full_block(36, input_dim, params.p_drop))\n",
    "    def forward(self,x):\n",
    "        y = self.encoder(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9363d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SEDR_test(100,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaff79c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEDR_test(\n",
       "  (encoder): Sequential(\n",
       "    (encoder_L1): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (encoder_L2): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=20, bias=True)\n",
       "      (1): BatchNorm1d(20, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (decoder_L0): Sequential(\n",
       "      (0): Linear(in_features=36, out_features=100, bias=True)\n",
       "      (1): BatchNorm1d(100, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c682a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20078e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "254513e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-768f9e89b423>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSEDR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "SEDR(100,self.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba277826",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential()\n",
    "encoder.add_module('encoder_L1', full_block(100, 50,params.p_drop))\n",
    "encoder.add_module('encoder_L2', full_block(50, 20, params.p_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17972307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_modules at 0x00000280A0BF6F90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in encoder.named_modules():\n",
    "#    print(i)\n",
    "encoder.named_modules()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9e77eb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0398,  0.0596,  0.0063,  ..., -0.0761, -0.0071,  0.0154],\n",
      "        [ 0.0242,  0.0341,  0.0111,  ..., -0.0178, -0.0128,  0.0679],\n",
      "        [ 0.0547, -0.0260,  0.0343,  ...,  0.0526, -0.0265,  0.0586],\n",
      "        ...,\n",
      "        [ 0.0838,  0.0486,  0.0251,  ...,  0.0362,  0.0768,  0.0556],\n",
      "        [ 0.0663, -0.0754,  0.0989,  ..., -0.0893, -0.0996, -0.0353],\n",
      "        [ 0.0697, -0.0113, -0.0772,  ..., -0.0789,  0.0072,  0.0370]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0174,  0.0251,  0.0834,  0.0598,  0.0737,  0.0599, -0.0240, -0.0129,\n",
      "        -0.0296, -0.0206, -0.0493,  0.0003, -0.0232, -0.0587,  0.0162,  0.0702,\n",
      "        -0.0300, -0.0727,  0.0570,  0.0769, -0.0389, -0.0754, -0.0159,  0.0649,\n",
      "         0.0926, -0.0557, -0.0023,  0.0374, -0.0850, -0.0084, -0.0154,  0.0149,\n",
      "        -0.0207,  0.0986, -0.0535,  0.0821,  0.0571, -0.0289, -0.0664,  0.0059,\n",
      "         0.0039, -0.0785,  0.0719,  0.0834, -0.0827, -0.0623,  0.0697,  0.0198,\n",
      "        -0.0020,  0.0860], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.7359e-02, -6.0184e-02,  3.7860e-02,  7.9859e-02,  1.2928e-01,\n",
      "          4.8126e-02,  4.4181e-02,  7.8042e-02, -9.4430e-02,  4.3410e-02,\n",
      "         -1.2869e-01, -1.3431e-02, -2.4059e-02, -2.9281e-02,  1.0868e-01,\n",
      "         -2.5892e-02, -1.3169e-01, -1.3145e-02, -1.3796e-01,  1.0012e-01,\n",
      "          1.8319e-03, -6.2744e-02, -7.6001e-02, -2.8217e-02,  4.6678e-02,\n",
      "         -2.4819e-02,  7.7686e-02,  1.1796e-01, -1.7806e-02,  9.1342e-02,\n",
      "         -4.2810e-02, -1.2499e-01,  5.3201e-03,  1.3646e-01,  1.4110e-01,\n",
      "          4.1601e-02,  1.1991e-01, -1.3346e-01,  3.7651e-02, -1.0725e-01,\n",
      "          6.3919e-02,  7.1009e-02, -4.9396e-02,  9.4138e-02, -1.2481e-01,\n",
      "          7.6873e-02, -7.6656e-02,  1.2600e-01, -9.9555e-02, -4.8364e-03],\n",
      "        [-2.2008e-04, -6.9276e-02, -5.7445e-03,  1.1396e-02,  2.6032e-02,\n",
      "          9.1894e-02,  1.2536e-01, -1.4113e-02,  9.1840e-02,  9.6390e-02,\n",
      "         -8.1850e-02, -1.1464e-01,  5.8400e-02,  5.1645e-02,  1.1330e-01,\n",
      "          4.7395e-02,  3.9132e-02,  4.4845e-02,  1.0834e-01, -6.6123e-02,\n",
      "          6.0730e-02, -1.2213e-01, -1.2185e-01,  1.0227e-01,  1.1829e-01,\n",
      "         -1.2152e-01,  5.7226e-02,  1.2152e-01, -7.3083e-02,  1.2733e-01,\n",
      "         -5.2508e-02, -5.7175e-02,  8.8684e-03,  1.0882e-01,  1.3237e-01,\n",
      "         -1.0042e-01,  6.8312e-02, -8.3712e-02, -5.3431e-02, -5.0297e-02,\n",
      "         -8.7398e-02, -8.2237e-02,  1.0353e-01, -7.3919e-02,  3.5803e-02,\n",
      "         -4.5892e-02,  1.9991e-03,  7.4857e-02,  2.5225e-03,  1.1275e-01],\n",
      "        [ 5.6361e-02, -1.4608e-03, -1.3209e-01,  5.8413e-02, -7.8048e-02,\n",
      "         -4.0060e-02,  1.1315e-03, -3.8865e-02,  1.0667e-01, -2.2890e-02,\n",
      "         -4.5250e-02,  5.3417e-02, -9.6201e-02,  5.4970e-02, -8.5337e-02,\n",
      "          2.7305e-02,  1.2362e-01, -7.0440e-02,  2.3996e-02, -2.9636e-02,\n",
      "          1.2721e-01,  1.3041e-01,  1.2207e-01,  1.6685e-02, -2.3143e-02,\n",
      "         -3.6768e-02,  4.7866e-02,  5.6225e-02,  8.2051e-02,  1.8448e-03,\n",
      "          6.1198e-02,  1.0204e-01, -2.6465e-03,  1.0256e-01,  3.3535e-02,\n",
      "         -3.7195e-02,  1.1916e-01, -1.1233e-01,  1.3272e-01, -4.5563e-02,\n",
      "          1.0788e-02,  2.6506e-02,  4.5555e-02, -5.0585e-02, -2.0168e-02,\n",
      "          1.0666e-01, -5.6222e-02,  1.1664e-01,  3.2893e-02, -1.4134e-01],\n",
      "        [ 6.7295e-02,  1.2415e-01, -1.3552e-01,  6.1214e-02,  5.5197e-02,\n",
      "         -3.5126e-02, -8.5367e-03,  2.0949e-02, -2.1900e-03,  1.0846e-01,\n",
      "          1.3189e-01, -5.6865e-02,  1.1887e-01,  6.5444e-04, -8.1780e-02,\n",
      "          1.2301e-01, -4.6365e-02, -1.9725e-02,  8.6255e-02,  1.3252e-01,\n",
      "          5.9627e-02,  1.2866e-01, -4.8105e-02,  3.6441e-02, -1.1036e-02,\n",
      "          1.0484e-01, -1.9871e-02,  3.4233e-03,  2.3665e-02, -6.9386e-02,\n",
      "          5.3781e-02, -7.3620e-03, -1.2482e-01,  2.8158e-02, -5.1530e-02,\n",
      "          6.4493e-02,  9.9963e-02, -1.0551e-01, -1.0348e-01,  5.2935e-04,\n",
      "         -1.3218e-01,  1.1524e-01, -6.0310e-02, -8.9673e-02,  5.6685e-02,\n",
      "          2.8224e-02, -3.8468e-03, -2.9923e-04, -1.0155e-01, -7.8984e-03],\n",
      "        [ 7.5900e-02,  1.1079e-01,  8.6937e-02, -1.3778e-01,  2.1677e-02,\n",
      "          6.8570e-02, -1.0811e-02, -3.4549e-02, -6.3223e-02, -1.2656e-01,\n",
      "         -4.5884e-02,  1.2407e-01, -6.8010e-02,  5.9879e-02, -1.4010e-01,\n",
      "         -8.6387e-02, -3.6516e-02, -2.6835e-02,  2.5254e-02,  4.6927e-02,\n",
      "         -6.1297e-03, -4.4844e-02,  6.9084e-02,  4.1313e-02, -8.6393e-03,\n",
      "         -2.0068e-02, -7.7894e-02,  1.1435e-01,  1.1973e-01, -1.1472e-01,\n",
      "          5.8235e-02, -1.5769e-02, -7.8100e-02, -7.7862e-02, -1.4075e-01,\n",
      "          1.4014e-01, -1.3889e-01,  6.7722e-02, -2.9408e-02,  1.0966e-01,\n",
      "          2.9796e-02, -1.0909e-01, -1.3614e-01,  8.3862e-02,  5.8433e-02,\n",
      "         -1.2620e-01, -3.8673e-02, -4.2042e-03,  1.1465e-01,  2.9319e-03],\n",
      "        [-9.4297e-02, -7.5224e-02, -1.1154e-01, -4.4403e-02, -1.1904e-01,\n",
      "          1.1984e-01, -1.7186e-02,  8.7030e-02, -6.7486e-02,  8.3943e-02,\n",
      "         -9.9429e-02, -3.2769e-02,  3.4514e-02, -6.2419e-02,  9.6154e-02,\n",
      "          3.6761e-02,  1.3086e-01, -2.4380e-02,  2.4223e-02,  4.8265e-02,\n",
      "          7.6679e-02,  1.3555e-01,  4.0386e-02,  8.1151e-03,  4.5555e-03,\n",
      "          3.1899e-02,  1.5634e-03,  3.0723e-02, -5.7088e-02,  1.1730e-02,\n",
      "          1.0461e-02, -4.3590e-02, -1.1042e-01, -3.4128e-02, -2.3598e-02,\n",
      "         -1.3468e-01, -9.9144e-02, -1.9345e-02,  7.2106e-02,  5.9382e-02,\n",
      "          1.0833e-01, -7.8702e-02,  4.0090e-02, -3.4775e-02, -6.4313e-02,\n",
      "         -8.6057e-02,  2.5035e-02, -3.2419e-02,  9.0444e-02, -1.0393e-01],\n",
      "        [ 6.7273e-02, -4.6048e-02,  1.4766e-02, -1.3039e-01,  7.2313e-02,\n",
      "         -9.1307e-02,  7.2706e-02,  1.2584e-01, -1.0679e-01,  7.8464e-02,\n",
      "          6.2287e-02,  1.0533e-01,  8.8927e-02, -1.1670e-01,  2.6061e-02,\n",
      "         -9.2734e-02, -7.1249e-02, -1.2953e-01, -1.3904e-01,  1.1994e-01,\n",
      "         -2.0895e-02,  1.0534e-01, -3.0859e-02, -1.1919e-01, -1.3627e-01,\n",
      "         -8.3173e-02,  1.0036e-01,  6.3504e-02, -3.6546e-02, -3.6030e-02,\n",
      "          1.0673e-01, -9.4889e-02, -6.4494e-02,  3.6545e-02,  9.9103e-02,\n",
      "          4.6073e-02,  3.9767e-02, -5.0519e-03, -1.2494e-01, -9.0652e-02,\n",
      "          2.8288e-03, -3.4501e-02,  1.2679e-01,  1.2695e-01, -1.3700e-02,\n",
      "          1.3459e-01,  4.6448e-02,  7.6309e-02,  6.3533e-02,  5.5479e-02],\n",
      "        [ 1.9252e-02,  4.9763e-02, -1.6183e-02, -1.4067e-01, -9.1760e-02,\n",
      "         -4.5224e-02, -4.3350e-02, -8.2960e-02, -4.4685e-02,  3.3430e-02,\n",
      "         -6.7147e-02,  6.9768e-02, -2.0134e-02,  1.1956e-01, -7.6208e-02,\n",
      "          7.9942e-02, -6.4700e-02, -6.6530e-02,  1.1680e-01,  6.1848e-02,\n",
      "         -8.2484e-02,  6.2940e-02, -1.1582e-01,  9.1646e-02, -1.0914e-01,\n",
      "          3.3994e-02, -1.2507e-01,  7.9921e-02,  1.6387e-03,  9.2300e-02,\n",
      "          1.2255e-01,  9.9780e-02, -1.6981e-02,  1.2922e-01,  2.7715e-03,\n",
      "          6.8738e-02,  5.0225e-02,  5.4186e-03, -5.1289e-02, -2.7632e-02,\n",
      "          3.4231e-02, -2.2885e-02,  2.8133e-02,  1.4700e-02,  5.2369e-02,\n",
      "         -6.5947e-02, -1.2976e-01, -6.8365e-02,  2.5110e-02,  2.9212e-02],\n",
      "        [ 3.9881e-02, -8.3060e-02,  5.5877e-02, -3.5645e-02, -9.4797e-02,\n",
      "          3.9650e-02, -7.4758e-02,  1.3657e-01, -5.9305e-03, -7.7154e-02,\n",
      "          1.2980e-01,  1.4053e-01, -1.3434e-01, -5.7135e-02, -6.8060e-02,\n",
      "         -1.5818e-02,  8.5251e-02, -1.1593e-01, -6.6817e-02, -6.5686e-02,\n",
      "          1.1951e-01, -9.5119e-02,  5.5437e-02,  2.8704e-02, -1.3722e-01,\n",
      "          9.3256e-02,  7.4732e-03, -6.3774e-03, -9.0431e-03,  1.3581e-01,\n",
      "          9.3745e-02, -1.3957e-01,  2.8262e-02,  6.3955e-02,  1.3600e-01,\n",
      "          1.0872e-01,  7.7168e-02,  6.5852e-02, -1.2189e-01, -9.1188e-02,\n",
      "         -1.3748e-01, -1.0559e-01,  2.7798e-02, -5.1260e-02,  5.2001e-02,\n",
      "         -7.5464e-02, -1.3349e-01,  1.2155e-01,  6.2372e-02,  5.0962e-02],\n",
      "        [ 3.8649e-02,  1.4013e-01,  1.2612e-01,  7.5790e-02, -1.0161e-01,\n",
      "         -4.5337e-02,  1.0376e-01, -7.9832e-02,  1.0798e-01,  9.6314e-02,\n",
      "          3.1770e-02,  1.1636e-01, -6.9427e-02, -4.2621e-02, -8.9991e-02,\n",
      "         -6.6855e-02, -4.9266e-02,  4.7500e-02, -5.5354e-02, -1.3467e-01,\n",
      "         -7.2814e-02,  5.4533e-02, -1.2088e-01,  2.1453e-02,  1.4085e-01,\n",
      "         -1.3122e-01, -2.8361e-02,  1.3933e-01,  1.1879e-01,  8.6417e-02,\n",
      "         -2.6897e-03, -1.0970e-01, -8.4783e-02,  5.1424e-02,  9.9374e-02,\n",
      "         -2.9576e-02, -1.2572e-01, -1.4033e-01, -6.0615e-02, -7.7669e-02,\n",
      "         -4.5670e-02, -1.3896e-01, -5.8286e-02, -1.0261e-01,  3.3460e-02,\n",
      "          1.3833e-01,  1.0001e-01, -9.8141e-02, -1.1435e-01,  9.6833e-02],\n",
      "        [-1.1467e-02,  7.0807e-02, -6.2763e-03, -7.3709e-03,  4.1424e-02,\n",
      "          2.7938e-02, -1.1465e-01,  9.5702e-02, -1.1983e-01,  8.8298e-02,\n",
      "         -4.1532e-02,  1.0395e-01,  1.0653e-01, -1.5766e-02, -8.9742e-02,\n",
      "         -1.2483e-02, -1.0757e-01, -2.0065e-02,  5.3780e-02, -1.0996e-01,\n",
      "         -7.0883e-02,  9.2785e-02,  4.4109e-02,  2.9924e-02, -4.9191e-02,\n",
      "          3.1684e-04, -5.7697e-02,  1.6199e-02,  9.3550e-02,  3.5133e-03,\n",
      "         -8.1719e-02, -8.7705e-02, -1.3327e-01,  8.9620e-02,  9.9527e-02,\n",
      "         -1.3723e-01, -8.5750e-02, -4.7141e-02,  1.5291e-02, -8.0604e-02,\n",
      "          6.8385e-02, -6.4785e-02,  7.7685e-02,  1.4137e-01,  9.6171e-02,\n",
      "          1.3381e-01,  4.0261e-02, -1.1173e-01,  1.3086e-01,  1.3104e-01],\n",
      "        [ 7.2327e-02,  3.8471e-02, -1.0503e-01, -1.3008e-01,  6.3235e-02,\n",
      "         -4.7026e-02, -4.5645e-02, -1.1350e-01,  8.4695e-03, -3.7124e-02,\n",
      "         -1.0198e-01,  8.0333e-03,  8.2660e-03, -6.5622e-02,  9.9801e-02,\n",
      "         -7.3218e-02, -5.6738e-02, -3.8469e-03,  9.7233e-02,  1.1232e-01,\n",
      "          4.4706e-02, -1.2489e-01, -2.5353e-02,  1.1242e-01,  4.7972e-02,\n",
      "         -3.0370e-02,  2.9159e-03,  1.3484e-01, -1.1361e-02,  6.9546e-02,\n",
      "         -9.1161e-02, -8.0433e-02, -5.0474e-02, -4.3352e-02, -9.5275e-02,\n",
      "          1.3058e-01,  1.1137e-01, -1.2507e-01,  1.1219e-01,  2.1930e-02,\n",
      "          8.9547e-03, -1.2942e-01,  2.2390e-02, -1.3394e-01,  1.2281e-01,\n",
      "          1.1160e-01,  2.0802e-02, -1.3371e-01,  9.4401e-02, -9.5722e-02],\n",
      "        [ 6.7847e-02,  3.2123e-02,  5.9741e-02, -1.3688e-01,  1.3293e-01,\n",
      "         -3.8752e-03,  1.0141e-01, -1.3985e-01, -1.1820e-01, -1.0146e-01,\n",
      "         -8.3862e-04,  4.0018e-02,  3.6733e-02,  5.9779e-02, -1.3444e-01,\n",
      "         -1.0003e-01,  1.2567e-01, -8.6526e-02, -8.0863e-03, -3.1308e-02,\n",
      "         -1.1413e-01,  1.0767e-01,  8.8872e-02, -1.1573e-01, -1.2621e-01,\n",
      "         -7.6196e-03, -1.3750e-01,  1.1502e-01, -1.3131e-01, -7.3767e-02,\n",
      "          1.6839e-02,  1.0399e-01, -2.6292e-02, -6.6686e-02, -5.5542e-02,\n",
      "          2.1578e-02, -7.1061e-02, -3.4589e-03, -8.9985e-02, -1.1569e-01,\n",
      "         -4.7214e-02,  6.7181e-02,  6.7508e-02,  2.9365e-02, -2.5856e-02,\n",
      "         -5.7429e-02,  9.4073e-02, -3.0287e-02, -1.1137e-01, -4.2917e-02],\n",
      "        [-9.7973e-02,  1.0281e-01,  1.1029e-01, -3.5577e-02,  1.1908e-01,\n",
      "         -7.5245e-02,  6.7360e-02,  6.7297e-02,  1.6266e-02, -1.1819e-01,\n",
      "         -2.3241e-02,  5.3243e-03, -1.2452e-01, -4.2005e-02, -9.7865e-02,\n",
      "          9.3160e-02,  4.1564e-02,  1.1867e-03, -5.2894e-02,  1.3028e-01,\n",
      "          6.1189e-02,  6.5798e-02,  9.4954e-02, -7.7257e-02,  9.6619e-02,\n",
      "         -1.9080e-03,  9.3854e-02, -3.7744e-02, -2.3827e-02,  3.3524e-02,\n",
      "         -6.2997e-02, -1.0632e-02, -1.1307e-01,  1.1334e-01, -8.0073e-02,\n",
      "         -7.8845e-02, -1.8113e-02, -7.0893e-02,  1.2010e-02,  7.1749e-02,\n",
      "         -3.0812e-02,  1.2886e-01, -7.0909e-02, -1.2047e-01,  1.1890e-01,\n",
      "          1.6628e-04,  4.0698e-02, -8.7219e-02,  9.2568e-02, -1.1843e-01],\n",
      "        [-1.3713e-02, -2.5337e-02, -4.1145e-03,  1.0166e-01, -2.5715e-02,\n",
      "         -3.1283e-02, -9.2453e-02, -1.1166e-01, -5.4954e-02,  4.2897e-02,\n",
      "          1.1688e-02,  6.5755e-02,  8.6982e-02,  1.2869e-01, -1.2387e-01,\n",
      "         -1.3479e-01, -1.9980e-02,  1.2420e-01, -1.0703e-01, -7.9336e-02,\n",
      "         -3.8838e-02,  1.2010e-01, -8.0287e-02,  5.4627e-02, -1.3746e-01,\n",
      "          1.0607e-01, -1.2858e-01, -4.9798e-02, -9.1433e-02, -1.1968e-01,\n",
      "          1.1172e-01, -6.2152e-02,  1.1425e-01, -2.7703e-02,  1.3755e-01,\n",
      "         -4.3711e-02,  1.1131e-01,  7.1126e-02,  3.5419e-02, -5.8379e-02,\n",
      "          2.0855e-02,  2.0376e-02, -9.1406e-02,  1.5080e-03,  6.1143e-02,\n",
      "         -1.1391e-01, -1.0348e-01, -1.3405e-01,  1.1759e-01, -7.8126e-02],\n",
      "        [-8.2161e-02, -8.5016e-02, -1.2876e-01,  5.1824e-02,  4.0400e-02,\n",
      "          8.5337e-02,  4.7484e-03,  1.3029e-01, -5.3716e-02, -7.7996e-02,\n",
      "          4.7501e-02,  8.7115e-02, -2.6137e-05,  1.0729e-01,  8.6358e-03,\n",
      "         -1.0245e-01,  1.4068e-02, -1.1532e-02, -1.4296e-02, -9.4144e-02,\n",
      "          1.1368e-01, -1.0007e-02, -1.2999e-01, -1.0654e-01, -1.2931e-01,\n",
      "          9.3096e-02, -1.3469e-01, -1.0768e-01,  1.3070e-01, -8.1414e-02,\n",
      "         -1.0475e-01,  6.4526e-02,  9.7559e-02, -8.5730e-02, -1.1370e-01,\n",
      "          4.9379e-02,  9.5064e-02, -6.2107e-02, -9.7149e-02,  8.1302e-02,\n",
      "          5.3751e-02,  9.0494e-02,  2.1816e-02, -4.3076e-02,  4.7187e-02,\n",
      "          3.9241e-02,  1.3743e-01,  1.3281e-01,  8.9852e-02, -1.3962e-01],\n",
      "        [-1.2492e-01, -8.4562e-02, -7.0965e-02,  7.1616e-02,  1.3485e-01,\n",
      "         -7.3418e-02, -1.8232e-02,  4.5895e-02,  6.6918e-02,  1.8507e-02,\n",
      "         -1.1479e-01,  8.5919e-02,  1.0051e-01, -6.6461e-02,  3.3906e-02,\n",
      "         -5.0725e-02,  1.4070e-01, -1.3784e-01, -4.7136e-02,  3.8497e-02,\n",
      "          3.3367e-02,  2.8059e-02,  5.0858e-02, -8.5105e-02,  9.9468e-02,\n",
      "          6.9115e-02, -3.4995e-02,  3.4672e-02,  8.0106e-02,  9.6964e-02,\n",
      "         -1.2847e-01,  8.9224e-02,  9.0068e-02,  8.0849e-02, -1.0078e-01,\n",
      "          6.2273e-02,  6.5729e-02, -3.4595e-02,  2.1641e-02, -3.6466e-02,\n",
      "         -1.0037e-01,  7.0296e-03, -4.9645e-02, -2.4121e-02,  1.3187e-01,\n",
      "         -1.0325e-01, -6.1411e-02,  2.4109e-02, -1.3449e-01, -9.7208e-02],\n",
      "        [ 8.6994e-02,  5.2474e-02,  8.9652e-02,  4.1050e-02,  6.1113e-03,\n",
      "          7.8048e-03, -2.6777e-05, -4.7877e-05,  3.1759e-02, -1.3400e-03,\n",
      "          1.0516e-01, -1.1381e-01,  1.2659e-01,  1.3719e-02,  1.0685e-01,\n",
      "          5.4753e-02, -8.6764e-02,  1.3029e-01, -1.3072e-01, -6.2273e-03,\n",
      "          1.2717e-01,  5.5287e-02, -1.7707e-02,  5.1569e-02,  2.2717e-02,\n",
      "         -4.3925e-03,  7.8517e-03, -9.9495e-02,  1.2276e-01, -5.5060e-02,\n",
      "         -1.2845e-01,  4.1275e-02, -5.0790e-03, -1.2275e-01,  1.0591e-01,\n",
      "         -1.1594e-01, -2.6286e-02, -6.8619e-02,  1.2065e-01, -9.4554e-02,\n",
      "         -6.9318e-02, -9.5707e-02,  9.8390e-02, -9.0552e-02,  4.4364e-02,\n",
      "         -7.8181e-02, -2.5891e-02, -7.4617e-02, -1.3367e-01, -1.1218e-01],\n",
      "        [-7.4483e-02,  1.1253e-01, -6.0908e-03,  5.4988e-02,  5.4587e-02,\n",
      "         -1.2122e-01, -4.4399e-02, -7.1669e-02,  1.2424e-01, -7.1068e-02,\n",
      "         -1.0453e-01,  1.3461e-02, -1.1505e-01, -1.3725e-01, -1.4075e-01,\n",
      "          8.7578e-02, -1.2440e-01, -4.7617e-02, -1.1173e-01,  1.2210e-01,\n",
      "          6.6467e-02, -8.3493e-02,  1.1823e-01,  8.6790e-02,  3.2279e-03,\n",
      "          4.2995e-02,  9.0288e-02,  7.9885e-02,  1.1790e-01,  2.4667e-02,\n",
      "          4.5903e-02,  1.8516e-02, -3.8365e-02, -6.7882e-02, -3.5379e-02,\n",
      "         -9.9070e-02,  1.2012e-02,  1.1764e-02, -1.1007e-01, -3.0130e-02,\n",
      "         -3.8679e-02, -5.9032e-02,  3.3549e-02, -4.8986e-02,  2.7799e-02,\n",
      "          5.1133e-02,  5.1464e-02,  2.6426e-02, -9.0372e-02, -6.7919e-02],\n",
      "        [-6.0285e-02,  6.2099e-02,  1.5262e-02, -8.6114e-02, -7.1350e-03,\n",
      "         -9.0473e-02,  5.2227e-02, -5.0967e-02, -1.3265e-01,  1.3170e-01,\n",
      "         -6.2316e-02, -9.5432e-02,  7.4052e-02,  5.5890e-02,  1.1691e-01,\n",
      "         -1.3069e-01,  1.3185e-01,  1.3800e-01, -8.5987e-02, -7.3965e-02,\n",
      "          1.6729e-02,  7.3537e-02, -7.9735e-02, -6.2617e-02, -7.9468e-02,\n",
      "          3.6449e-02, -4.1012e-02, -1.0430e-01,  6.6628e-02, -1.3936e-01,\n",
      "         -9.7967e-02,  9.6148e-02,  9.5415e-02, -5.6152e-02,  1.2631e-02,\n",
      "         -1.0276e-01, -9.2994e-02, -1.1737e-01,  9.0723e-02, -9.1325e-03,\n",
      "         -4.2994e-02, -4.1012e-02,  9.6918e-03, -8.2325e-02,  1.3068e-01,\n",
      "          1.9666e-02, -1.0160e-01, -1.1446e-02, -3.8300e-02,  1.1433e-01]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1084,  0.1108,  0.0115,  0.1014, -0.0329, -0.0066, -0.0790, -0.0417,\n",
      "        -0.0112,  0.1112, -0.1329,  0.0143, -0.0903, -0.0278, -0.0889,  0.0639,\n",
      "        -0.1002,  0.0739, -0.0084,  0.0504], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in encoder.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "122ace3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "913aed4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06871080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--k', type=int, default=10, help='parameter k in spatial graph')\n",
    "parser.add_argument('--knn_distanceType', type=str, default='euclidean',\n",
    "                    help='graph distance type: euclidean/cosine/correlation')\n",
    "parser.add_argument('--epochs', type=int, default=300, help='Number of epochs to train.')\n",
    "parser.add_argument('--cell_feat_dim', type=int, default=300, help='Dim of PCA')\n",
    "parser.add_argument('--feat_hidden1', type=int, default=100, help='Dim of DNN hidden 1-layer.')\n",
    "parser.add_argument('--feat_hidden2', type=int, default=20, help='Dim of DNN hidden 2-layer.')\n",
    "parser.add_argument('--gcn_hidden1', type=int, default=32, help='Dim of GCN hidden 1-layer.')\n",
    "parser.add_argument('--gcn_hidden2', type=int, default=8, help='Dim of GCN hidden 2-layer.')\n",
    "parser.add_argument('--p_drop', type=float, default=0.2, help='Dropout rate.')\n",
    "parser.add_argument('--using_dec', type=bool, default=True, help='Using DEC loss.')\n",
    "parser.add_argument('--using_mask', type=bool, default=True, help='Using mask for multi-dataset.')\n",
    "parser.add_argument('--feat_w', type=float, default=10, help='Weight of DNN loss.')\n",
    "parser.add_argument('--gcn_w', type=float, default=0.1, help='Weight of GCN loss.')\n",
    "parser.add_argument('--dec_kl_w', type=float, default=100, help='Weight of DEC loss.')\n",
    "parser.add_argument('--gcn_lr', type=float, default=0.01, help='Initial GNN learning rate.')\n",
    "parser.add_argument('--gcn_decay', type=float, default=0.01, help='Initial decay rate.')\n",
    "parser.add_argument('--dec_cluster_n', type=int, default=8, help='DEC cluster number.')\n",
    "parser.add_argument('--dec_interval', type=int, default=20, help='DEC interval nnumber.')\n",
    "parser.add_argument('--dec_tol', type=float, default=0.00, help='DEC tol.')\n",
    "# ______________ Eval clustering Setting _________\n",
    "parser.add_argument('--eval_resolution', type=int, default=1, help='Eval cluster number.')\n",
    "parser.add_argument('--eval_graph_n', type=int, default=20, help='Eval graph kN tol.') \n",
    "\n",
    "params = parser.parse_args(args=[])\n",
    "params.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1beef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(cell_feat_dim=300, dec_cluster_n=8, dec_interval=20, dec_kl_w=100, dec_tol=0.0, device='cuda:0', epochs=300, eval_graph_n=20, eval_resolution=1, feat_hidden1=100, feat_hidden2=20, feat_w=10, gcn_decay=0.01, gcn_hidden1=32, gcn_hidden2=8, gcn_lr=0.01, gcn_w=0.1, k=10, knn_distanceType='euclidean', p_drop=0.2, using_dec=True, using_mask=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bfd2e66",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SEDR' object has no attribute 'latent_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-af5ec968e936>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maaa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSEDR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-2e91bfcd00b7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, params)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decoder_L0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1130\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1131\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SEDR' object has no attribute 'latent_dim'"
     ]
    }
   ],
   "source": [
    "aaa = SEDR(100,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bff93a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
